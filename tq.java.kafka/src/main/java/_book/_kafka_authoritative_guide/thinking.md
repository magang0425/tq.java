2019-01-11

## Kafka

### 疑问
1. 如何有那么大的吞吐量的
2. 如何保证消息不丢失的
3. 如果保证消息投递的
4. 如何持久化的
1. 限流与流控
1. 性能瓶颈在哪里

### 思考
1. 一个主题内的消息如何分区
    - hash?
    - 轮询?
    - 应该是 一致性hash
1. 一个分区就是一个提交日志??
    - TODO
1. 群组保证每个分区只能被一个消费者使用
    - 如何保证??
        - 票据??
        - CAS??
2. 为消费者返回已经提交到磁盘上的消息
    - 消费数据受到 磁盘速度的影响??
        - TODO
3. 每个集群都有一个broker 同时充当集群控制器的角色(自动从集群中活跃的成员中选取出来)
    - 如何定义一个broker 是否是一个活跃的成员
    - 选举算法
4. 分区复制
    - 同步机制
    - TODO
5. 不可以减少分区个数的原因
    - TODO
6. 理解 log.retention.ms, log.retention.bytes, log.segment.bytes, log.segment.ms 之间的作用关系
7. 发送消息
    - 发送消息的过程中, key的作用
    - 如何重试
    - 如何确定发送成功
1. 消费
    - 如果群组中的消费者数量超过了主题的分区数量, 就有一部分消费者会被闲置
        - why
        - 顺序
1. 一个主题的分区数量是否有什么限制
1. 如果提交的偏移量小于客户端处理的最后一条消息的偏移量, 处理两个偏移量之间的消息就会被重复消费
    - 什么情况下会出现
    

